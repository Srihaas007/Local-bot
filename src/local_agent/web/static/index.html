<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Local Agent • Frontier 1899</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <!-- Western-esque font combo (open source) -->
  <link href="https://fonts.googleapis.com/css2?family=Cinzel:wght@600;700&family=Roboto+Slab:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/static/style.css" />
</head>
<body>
  <div id="sidebar">
    <div class="brand">
      <h1>LOCAL AGENT</h1>
      <div class="tag">FRONTIER OPS · 1899</div>
    </div>
    <div id="searchBox">
      <input type="text" id="searchInput" placeholder="Search memory..." />
      <button id="searchBtn">Search</button>
      <div id="memoryHits"></div>
    </div>
    <div id="voiceControls">
      <h3>Voice</h3>
      <div>
        <label>Upload WAV for STT:</label><br/>
        <input type="file" id="sttFile" accept="audio/wav" />
        <button id="sttBtn">Transcribe</button>
      </div>
      <div style="margin-top:12px;">
        <input type="text" id="ttsInput" placeholder="Text to speak" />
        <button id="ttsBtn">Play TTS</button>
        <audio id="ttsAudio" controls style="display:none;"></audio>
      </div>
        <div style="margin-top:18px;">
          <h4>Mic (live)</h4>
          <div>
            <button id="micStartBtn">Start Mic</button>
            <button id="micStopBtn" disabled>Stop & Transcribe</button>
          </div>
          <small id="micStatus" style="display:block; margin-top:6px; color:#bbb;">Idle</small>
          <audio id="micPlayback" controls style="display:none; margin-top:6px;"></audio>
        </div>
      <div class="footer-note">No proprietary assets used. Rustic theme inspired by the late 19th century.</div>
    </div>
  </div>
  <div id="main">
    <div id="messages"></div>
    <div id="inputBar">
      <input type="text" id="chatInput" placeholder="Type a message..." />
      <button id="sendBtn">Send</button>
      <button id="streamToggle">Streaming: ON</button>
      <button id="bangBtn" title="Bang Bang!">Bang!</button>
    </div>
    <div id="streamIndicator"></div>
  </div>

  <script>
    const messagesEl = document.getElementById('messages');
    const chatInput = document.getElementById('chatInput');
    const sendBtn = document.getElementById('sendBtn');
    const streamToggle = document.getElementById('streamToggle');
    const memoryHits = document.getElementById('memoryHits');
    let streamingEnabled = true;

    function addMessage(text, role) {
      const div = document.createElement('div');
      div.className = 'msg ' + role;
      div.textContent = text;
      div.setAttribute('data-role', role);
      messagesEl.appendChild(div);
      messagesEl.scrollTop = messagesEl.scrollHeight;
    }

    async function sendChat() {
      const msg = chatInput.value.trim();
      if (!msg) return;
      addMessage(msg, 'user');
      chatInput.value='';
      if (streamingEnabled) {
        streamChat(msg);
      } else {
        const resp = await fetch('/chat', {method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({message: msg})});
        const data = await resp.json();
        addMessage(data.output, 'assistant');
      }
    }

    function streamChat(msg) {
      const indicator = document.getElementById('streamIndicator');
      indicator.textContent = 'Streaming...';
      let buffer = '';
      const es = new EventSource('/chat/stream?message=' + encodeURIComponent(msg));
      es.onmessage = (e) => {
        buffer += e.data;
        renderStreaming(buffer);
      };
      es.addEventListener('tool', (e) => {
        buffer += '\n' + JSON.parse(e.data).name + ' requested. Approve via CLI (not supported in UI yet).';
        renderStreaming(buffer);
      });
      es.addEventListener('done', () => {
        finalizeStreaming(buffer);
        indicator.textContent = '';
        es.close();
      });
      es.addEventListener('error', () => {
        finalizeStreaming(buffer + '\n[stream error]');
        indicator.textContent = '';
        es.close();
      });
    }

    function renderStreaming(text) {
      // Update or create streaming assistant message
      let last = messagesEl.querySelector('.msg.assistant[data-streaming="true"]');
      if (!last) {
        last = document.createElement('div');
        last.className = 'msg assistant';
        last.dataset.streaming = 'true';
        messagesEl.appendChild(last);
      }
      last.textContent = text;
      messagesEl.scrollTop = messagesEl.scrollHeight;
    }

    function finalizeStreaming(text) {
      let last = messagesEl.querySelector('.msg.assistant[data-streaming="true"]');
      if (last) {
        last.removeAttribute('data-streaming');
        last.textContent = text;
      } else {
        addMessage(text, 'assistant');
      }
    }

    sendBtn.addEventListener('click', sendChat);
    chatInput.addEventListener('keydown', (e) => { if (e.key === 'Enter') sendChat(); });
    streamToggle.addEventListener('click', () => {
      streamingEnabled = !streamingEnabled;
      streamToggle.textContent = 'Streaming: ' + (streamingEnabled ? 'ON' : 'OFF');
    });

    // Bang button visual effect (muzzle flash + shake)
    const bangBtn = document.getElementById('bangBtn');
    bangBtn.addEventListener('click', () => {
      const flash = document.createElement('div');
      flash.className = 'muzzle-flash';
      document.body.appendChild(flash);
      setTimeout(()=> flash.remove(), 300);
      document.body.classList.add('screen-shake');
      setTimeout(()=> document.body.classList.remove('screen-shake'), 400);
      addMessage('*Bang!*', 'assistant');
    });

    // Memory search
    document.getElementById('searchBtn').addEventListener('click', async () => {
      const q = document.getElementById('searchInput').value.trim();
      if (!q) return; 
      const resp = await fetch('/memory/search?q=' + encodeURIComponent(q));
      const data = await resp.json();
      memoryHits.innerHTML = '';
      data.hits.forEach(h => {
        const d = document.createElement('div');
        d.className='hit';
        d.textContent = '[' + h.kind + '] ' + h.text;
        memoryHits.appendChild(d);
      });
    });

    // STT
    document.getElementById('sttBtn').addEventListener('click', async () => {
      const f = document.getElementById('sttFile').files[0];
      if (!f) return;
      const fd = new FormData();
      fd.append('file', f, f.name);
      const resp = await fetch('/stt', { method:'POST', body: fd });
      const data = await resp.json();
      addMessage('[STT] ' + (data.content || data.error), 'assistant');
    });

    // TTS
    document.getElementById('ttsBtn').addEventListener('click', async () => {
      const text = document.getElementById('ttsInput').value.trim();
      if (!text) return;
      const resp = await fetch('/tts?text=' + encodeURIComponent(text));
      if (!resp.ok) {
        addMessage('[TTS error] ' + (await resp.text()), 'assistant');
        return;
      }
      const blob = await resp.blob();
      const url = URL.createObjectURL(blob);
      const audio = document.getElementById('ttsAudio');
      audio.style.display='block';
      audio.src = url;
      audio.play();
    });

  // ===== Microphone capture (WAV builder) =====
    const micStartBtn = document.getElementById('micStartBtn');
    const micStopBtn  = document.getElementById('micStopBtn');
    const micStatus   = document.getElementById('micStatus');
    const micPlayback = document.getElementById('micPlayback');
    let audioCtx; let micStream; let sourceNode; let processorNode; let buffers = []; let recording = false;

    function mergeBuffers(bufferArrays, totalLength) {
      const result = new Float32Array(totalLength);
      let offset = 0;
      for (const arr of bufferArrays) { result.set(arr, offset); offset += arr.length; }
      return result;
    }
    function floatTo16BitPCM(floatBuf) {
      const out = new DataView(new ArrayBuffer(floatBuf.length * 2));
      let offset = 0;
      for (let i=0;i<floatBuf.length;i++) {
        let s = Math.max(-1, Math.min(1, floatBuf[i]));
        s = s < 0 ? s * 0x8000 : s * 0x7FFF;
        out.setInt16(offset, s, true); offset += 2;
      }
      return out.buffer;
    }
    function encodeWAV(samples, sampleRate) {
      const buffer = new ArrayBuffer(44 + samples.length * 2);
      const view = new DataView(buffer);
      const writeString = (offset, str) => { for (let i=0;i<str.length;i++) view.setUint8(offset+i, str.charCodeAt(i)); };
      // RIFF header
      writeString(0,'RIFF');
      view.setUint32(4, 36 + samples.length * 2, true);
      writeString(8,'WAVE');
      writeString(12,'fmt ');
      view.setUint32(16,16,true); // Subchunk1Size
      view.setUint16(20,1,true);  // PCM
      view.setUint16(22,1,true);  // mono
      view.setUint32(24,sampleRate,true);
      view.setUint32(28,sampleRate*2,true); // byte rate (sampleRate * numChannels * bytesPerSample)
      view.setUint16(32,2,true); // block align
      view.setUint16(34,16,true); // bits per sample
      writeString(36,'data');
      view.setUint32(40, samples.length * 2, true);
      // PCM samples
      const pcm = new DataView(buffer, 44);
      const floatBuf = samples;
      let idx = 0;
      for (let i=0;i<floatBuf.length;i++) {
        let s = Math.max(-1, Math.min(1, floatBuf[i]));
        s = s < 0 ? s * 0x8000 : s * 0x7FFF;
        pcm.setInt16(idx, s, true);
        idx += 2;
      }
      return new Blob([buffer], {type:'audio/wav'});
    }

    micStartBtn.addEventListener('click', async () => {
      if (recording) return;
      try {
        micStream = await navigator.mediaDevices.getUserMedia({audio:true});
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        sourceNode = audioCtx.createMediaStreamSource(micStream);
        processorNode = audioCtx.createScriptProcessor(4096,1,1);
        buffers = []; recording = true;
        processorNode.onaudioprocess = (e) => {
          if (!recording) return;
          const channelData = e.inputBuffer.getChannelData(0);
          buffers.push(new Float32Array(channelData));
        };
        sourceNode.connect(processorNode);
        processorNode.connect(audioCtx.destination);
        micStatus.textContent = 'Recording...';
        micStartBtn.disabled = true;
        micStopBtn.disabled = false;
      } catch (err) {
        micStatus.textContent = 'Mic error: ' + err;
      }
    });

    micStopBtn.addEventListener('click', async () => {
      if (!recording) return;
      recording = false;
      micStartBtn.disabled = false;
      micStopBtn.disabled = true;
      micStatus.textContent = 'Processing...';
      try {
        processorNode && processorNode.disconnect();
        sourceNode && sourceNode.disconnect();
        micStream && micStream.getTracks().forEach(t => t.stop());
      } catch {}
      const length = buffers.reduce((a,b)=>a+b.length,0);
      const merged = mergeBuffers(buffers, length);
      const wavBlob = encodeWAV(merged, audioCtx.sampleRate);
      micPlayback.style.display='block';
      micPlayback.src = URL.createObjectURL(wavBlob);
      // Upload for STT
      const fd = new FormData();
      fd.append('file', wavBlob, 'live.wav');
      const resp = await fetch('/stt', {method:'POST', body: fd});
      const data = await resp.json();
      addMessage('[Live STT] ' + (data.content || data.error), 'assistant');
      micStatus.textContent = 'Idle';
    });
  </script>
</body>
</html>